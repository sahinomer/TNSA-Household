% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={TNSA Household Wealth Index},
  pdfauthor={Ömer Şahin},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{TNSA Household Wealth Index}
\author{Ömer Şahin}
\date{}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

2013 Turkey Demographic and Health Survey (TDHS-2013), fertility levels
and trends, infant and child mortality, family planning and maternal and
child health issues a sample survey at the national level designed to
provide information on. And also, gives information about the wealth
index of the household. In this work, the wealth index analysis and
prediction according to other information about a household are
evaluated.

\hypertarget{data-analyze}{%
\section{Data Analyze}\label{data-analyze}}

\hypertarget{libraries}{%
\paragraph{Libraries}\label{libraries}}

Required libraries for data preparation and analyze:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readr)    }\CommentTok{# Data loading }
\KeywordTok{library}\NormalTok{(tidyr)    }\CommentTok{# Seperate data column}
\KeywordTok{library}\NormalTok{(ggplot2)  }\CommentTok{# Visualize}
\end{Highlighting}
\end{Shaded}

\hypertarget{load-household-dataset}{%
\paragraph{Load Household Dataset}\label{load-household-dataset}}

Simplified household data of the TNSA dataset is loaded.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{file=}\StringTok{"household.csv"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{";"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na.strings =} \KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{ , }\StringTok{" "}\NormalTok{,}\StringTok{"}\CharTok{\textbackslash{}t}\StringTok{ "}\NormalTok{, }\StringTok{"Missing"}\NormalTok{ ))}
\end{Highlighting}
\end{Shaded}

Each household row has ``case\_id'' field. These values are unique for
each sample. The ID column is dropped due to has no contribution to the
training.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\NormalTok{household[, }\DecValTok{-1}\NormalTok{]  }\CommentTok{# drop case id}
\end{Highlighting}
\end{Shaded}

In house ownership column has only one ``Other'' feature. Therefore,
this row is evaluated as outliers and dropped.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\NormalTok{household[}\OperatorTok{-}\KeywordTok{which}\NormalTok{(household}\OperatorTok{$}\NormalTok{house_ownership }\OperatorTok{==}\StringTok{ "Other"}\NormalTok{), ]}
\NormalTok{household}\OperatorTok{$}\NormalTok{house_ownership <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(household}\OperatorTok{$}\NormalTok{house_ownership)}
\end{Highlighting}
\end{Shaded}

In this stage, the number of samples:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(household)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11793
\end{verbatim}

The dataset has some rows with unknown attributes. The number of rows
with missing values is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(}\OperatorTok{!}\KeywordTok{complete.cases}\NormalTok{(household))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 178
\end{verbatim}

The number of rows that are not complete can be ignored compared to the
total number of samples, and these samples are dropped.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\KeywordTok{na.omit}\NormalTok{(household)}
\end{Highlighting}
\end{Shaded}

At the end of the data clearing, the number of samples:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(household)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11615
\end{verbatim}

\hypertarget{combined-region}{%
\paragraph{Combined Region}\label{combined-region}}

The household data contain the combined region field that consists of a
combination of a cardinal direction, region, and settlement. These
fields are separated into three.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(household}\OperatorTok{$}\NormalTok{region_combined)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] West - Istanbul - Urban/Metropol West - Istanbul - Urban/Metropol
## [3] West - Istanbul - Urban/Metropol West - Istanbul - Urban/Metropol
## [5] West - Istanbul - Urban/Metropol West - Istanbul - Urban/Metropol
## 35 Levels: Central - Aegean - Rural ... West - West Marmara - Urban
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\KeywordTok{separate}\NormalTok{(household, region_combined, }\KeywordTok{c}\NormalTok{(}\StringTok{"cardinal_direction"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"settlement"}\NormalTok{), }\DataTypeTok{sep =} \StringTok{'-'}\NormalTok{)}
\NormalTok{household}\OperatorTok{$}\NormalTok{cardinal_direction <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(household}\OperatorTok{$}\NormalTok{cardinal_direction)}
\NormalTok{household}\OperatorTok{$}\NormalTok{region <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(household}\OperatorTok{$}\NormalTok{region)}
\NormalTok{household}\OperatorTok{$}\NormalTok{settlement <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(household}\OperatorTok{$}\NormalTok{settlement)}

\KeywordTok{head}\NormalTok{(household[, }\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   cardinal_direction     region      settlement
## 1              West   Istanbul   Urban/Metropol
## 2              West   Istanbul   Urban/Metropol
## 3              West   Istanbul   Urban/Metropol
## 4              West   Istanbul   Urban/Metropol
## 5              West   Istanbul   Urban/Metropol
## 6              West   Istanbul   Urban/Metropol
\end{verbatim}

\hypertarget{wealth-index}{%
\paragraph{Wealth Index}\label{wealth-index}}

The aim of this project is predicting the wealth index of the household.
There is an order between wealth index values. Therefore, wealth index
factor is releveled.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Refactor levels of wealth index}
\NormalTok{household}\OperatorTok{$}\NormalTok{wealth_index <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(household}\OperatorTok{$}\NormalTok{wealth_index, }
                                 \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Poorest"}\NormalTok{, }\StringTok{"Poorer"}\NormalTok{, }\StringTok{"Middle"}\NormalTok{, }\StringTok{"Richer"}\NormalTok{, }\StringTok{"Richest"}\NormalTok{))}
\KeywordTok{levels}\NormalTok{(household}\OperatorTok{$}\NormalTok{wealth_index)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Poorest" "Poorer"  "Middle"  "Richer"  "Richest"
\end{verbatim}

\hypertarget{attribute-relation}{%
\paragraph{Attribute Relation}\label{attribute-relation}}

Some attributes have a relation to each other. These relations can be
represented as a ratio between them. In this way, all household samples
will have attributes that in the same range even they are in the natural
number range. After extending columns with the rate of related ones,
duplicate columns are dropped.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Rate of related attributes}
\NormalTok{household}\OperatorTok{$}\NormalTok{man_member_rate =}\StringTok{ }\NormalTok{(household}\OperatorTok{$}\NormalTok{household_member }\OperatorTok{-}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{woman_member) }\OperatorTok{/}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{household_member}
\NormalTok{household}\OperatorTok{$}\NormalTok{woman_member_rate =}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{woman_member }\OperatorTok{/}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{household_member}
\NormalTok{household}\OperatorTok{$}\NormalTok{child_member_rate =}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{children_under_}\DecValTok{5} \OperatorTok{/}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{household_member}
\NormalTok{household}\OperatorTok{$}\NormalTok{bedroom_rate =}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{bedroom_number }\OperatorTok{/}\StringTok{ }\NormalTok{household}\OperatorTok{$}\NormalTok{rooms_number}

\CommentTok{# Drop duplicated columns with rate values}
\NormalTok{household <-}\StringTok{ }\NormalTok{household[ , }\OperatorTok{-}\KeywordTok{which}\NormalTok{(}\KeywordTok{names}\NormalTok{(household) }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"woman_member"}\NormalTok{,  }\CommentTok{# woman_member_rate}
                                                         \StringTok{"children_under_5"}\NormalTok{, }\CommentTok{# children_member_rate}
                                                         \StringTok{"bedroom_number"}\NormalTok{))]  }\CommentTok{# bedroom_rate}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-distribution}{%
\paragraph{Data Distribution}\label{data-distribution}}

The wealth index of a household is the target that is tried to predict.
The distribution of the wealth index is quite balanced. It helps to
ensure the model does not tend to a class when the target class is
balanced.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(household, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ wealth_index)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Wealth Index"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Number of Households"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{ggtitle}\NormalTok{(}\DataTypeTok{label =} \StringTok{"Wealth Index Distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-12-1.pdf}

Distributions of the some of binary attributes about households are too
imbalanced. There are not enough counter samples for these attributes.
Therefore, these attributes can misguide the model when predicting the
wealth index. Imbalanced attributes:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(household[, }\KeywordTok{c}\NormalTok{(}\StringTok{"refrigerator"}\NormalTok{, }\StringTok{"garbage_grinder"}\NormalTok{, }\StringTok{"washing_machine"}\NormalTok{, }\StringTok{"washer_dryer"}\NormalTok{, }
                      \StringTok{"home_theather"}\NormalTok{, }\StringTok{"mobile_phone"}\NormalTok{, }\StringTok{"taxi_minibus"}\NormalTok{, }\StringTok{"tractor"}\NormalTok{, }\StringTok{"motorcycle"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  refrigerator garbage_grinder washing_machine washer_dryer home_theather
##  No :  175    No :11544       No :  515       No :11411    No :11282    
##  Yes:11440    Yes:   71       Yes:11100       Yes:  204    Yes:  333    
##  mobile_phone taxi_minibus tractor     motorcycle 
##  No :  565    No :11126    No :10642   No :10806  
##  Yes:11050    Yes:  489    Yes:  973   Yes:  809
\end{verbatim}

According to results, nearly all households have a refrigerator, washing
machine, and a mobile phone. On the other hand, nearly none of the
households have the garbage grinder, washer dryer or home theatre. As a
result, these attributes are not used for training the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\NormalTok{household[ , }\OperatorTok{-}\KeywordTok{which}\NormalTok{(}\KeywordTok{names}\NormalTok{(household) }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"refrigerator"}\NormalTok{, }\StringTok{"garbage_grinder"}\NormalTok{,}
                                                         \StringTok{"washing_machine"}\NormalTok{, }\StringTok{"washer_dryer"}\NormalTok{, }
                                                         \StringTok{"home_theather"}\NormalTok{, }\StringTok{"mobile_phone"}\NormalTok{,}
                                                         \StringTok{"taxi_minibus"}\NormalTok{, }\StringTok{"tractor"}\NormalTok{, }\StringTok{"motorcycle"}\NormalTok{))]}
\end{Highlighting}
\end{Shaded}

Province column in the dataset is also imbalanced and has too many
different classes due to there are 81 cities in Turkey. Besides, the
Random Forest model cannot handle too many categories. Therefore, the
province column is dropped to evaluate other models in equal conditions.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(}\KeywordTok{summary}\NormalTok{(household}\OperatorTok{$}\NormalTok{province))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Adana Adiyaman    Afyon     Agri  Aksaray   Amasya 
##      441       84       35      162       75       39
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{household <-}\StringTok{ }\NormalTok{household[, }\OperatorTok{-}\KeywordTok{which}\NormalTok{(}\KeywordTok{names}\NormalTok{(household) }\OperatorTok{==}\StringTok{ "province"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\hypertarget{outliers}{%
\paragraph{Outliers}\label{outliers}}

TNSA Household dataset was collected under controlled by qualified
observers. Therefore, Obtained information about households is accepted
as truth. Information that does not have enough observations or balanced
distribution is not used in the analysis to make a proper evaluation.

\hypertarget{analyze}{%
\subsection{Analyze}\label{analyze}}

At the end of data preparation, data analyzing by visualizing is done
over some information about the household dataset.

The relation between wealth index and settlement area:

\includegraphics{report_files/figure-latex/unnamed-chunk-16-1.pdf}

Most of the people live in urban areas. On the other hand, when the
wealth index is reducing, people tend to live in rural areas or people
that live in rural areas are poorer than the others.

The relation between wealth index and house ownership:

\includegraphics{report_files/figure-latex/unnamed-chunk-17-1.pdf}

Contrary to expectation, poor households live in their own houses and
richer households may prefer to live in a rented house.

The relation between wealth index and owning another house:

\includegraphics{report_files/figure-latex/unnamed-chunk-18-1.pdf}

According to the data, people do not much interest in having another
house. Still, rich households much more have another house than the poor
ones as expected.

The relation between internet connection and wealth index:

\includegraphics{report_files/figure-latex/unnamed-chunk-19-1.pdf}

According to 2013 data, the internet connection is still not very
prevalent and seen as a luxury feature.

\hypertarget{classification}{%
\section{Classification}\label{classification}}

Each sample row contains 34 features about household and wealth index.
The wealth index of the household is the target value that is tried to
predict by the classifier. Different types of classifiers are compared
with others and itself that uses a different parameter set.

\hypertarget{libraries-1}{%
\paragraph{Libraries}\label{libraries-1}}

Required libraries for data classification and performace evaluation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(performanceEstimation)   }\CommentTok{# Performance estimation}
\KeywordTok{library}\NormalTok{(caret)         }\CommentTok{# Confusion matrix}
\KeywordTok{library}\NormalTok{(CORElearn)     }\CommentTok{# Feature extraction}
\KeywordTok{library}\NormalTok{(DMwR2)         }\CommentTok{# Decision tree}
\KeywordTok{library}\NormalTok{(rpart)         }\CommentTok{# Decision tree}
\KeywordTok{library}\NormalTok{(rpart.plot)    }\CommentTok{# Decision tree visualize}
\KeywordTok{library}\NormalTok{(e1071)         }\CommentTok{# Support vector machine}
\KeywordTok{library}\NormalTok{(randomForest)  }\CommentTok{# Random forest}
\KeywordTok{library}\NormalTok{(adabag)        }\CommentTok{# Adabag}
\KeywordTok{library}\NormalTok{(h2o)           }\CommentTok{# Neural network}
\end{Highlighting}
\end{Shaded}

\hypertarget{split-traintest-set}{%
\paragraph{Split Train/Test Set}\label{split-traintest-set}}

Randomly selected 20 percent of the dataset is used as a test and the
rest of them are used for training models.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1024}\NormalTok{)}
\NormalTok{samples <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(household), }\KeywordTok{nrow}\NormalTok{(household)}\OperatorTok{*}\FloatTok{0.8}\NormalTok{)}
\NormalTok{train <-}\StringTok{ }\NormalTok{household[samples, ]}
\NormalTok{test <-}\StringTok{ }\NormalTok{household[}\OperatorTok{-}\NormalTok{samples, ]}
\end{Highlighting}
\end{Shaded}

\hypertarget{analyze-decision-boundary}{%
\subsubsection{Analyze Decision
Boundary}\label{analyze-decision-boundary}}

By using a simple decision tree, tried to understand the decision
boundary for classification household dataset according to the wealth
index.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{decision_tree <-}\StringTok{ }\KeywordTok{rpartXse}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., }
\NormalTok{                          train[,}\KeywordTok{c}\NormalTok{(}\StringTok{"wealth_index"}\NormalTok{, }\StringTok{"heating"}\NormalTok{, }\StringTok{"dishwasher"}\NormalTok{, }
                                   \StringTok{"internet"}\NormalTok{, }\StringTok{"settlement"}\NormalTok{)], }\DataTypeTok{se =} \DecValTok{1}\NormalTok{)}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(decision_tree, test, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{)}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(predicted, test}\OperatorTok{$}\NormalTok{wealth_index)}
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     366     97      6      0       0
##    Poorer      139    259     72      6       0
##    Middle       24    160    225     95       9
##    Richer        1     12    125    227      59
##    Richest       0      0      5    117     319
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Accuracy 
## 0.6009471
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rpart.plot}\NormalTok{(decision_tree)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-22-1.pdf}

Asking a household member about settlement area that they are living,
their heating method, whether they have dishwasher and internet
connection gives an idea of the wealth index of the household by mostly
misclassified only one level different. After all, a better
classification model is required for more success. Even attributes that
have high information gain are selected, the wealth index cannot be
predicted directly by using some partition of attributes.

\hypertarget{decision-tree}{%
\subsubsection{Decision Tree}\label{decision-tree}}

The first model is the decision tree. Optimum parameters are selected by
using a performance estimator. The model is trained with this parameter
set and the test set is predicted by the model. Parameters are
information gain threshold and prune value. Features are sorted by their
information gain and thresholded by a value to reduce the number of
features. Features are kept if their information gain value is greater
than the threshold. Decision tree pruning is evaluated by given
parameters.

Parameter set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inf_gain <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.0}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\NormalTok{prune_se <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.0}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{1.0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\StringTok{"decisiontree.perf"}\NormalTok{)  }\CommentTok{# Load pre-estimated performances}
\KeywordTok{plot}\NormalTok{(perfEst)   }\CommentTok{# Plot performance estimation results}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/decisiontree-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Best parameter set}
\NormalTok{work_flow <-}\StringTok{ }\KeywordTok{getWorkflow}\NormalTok{(}\KeywordTok{topPerformers}\NormalTok{(perfEst, }\DataTypeTok{maxs =} \OtherTok{TRUE}\NormalTok{)[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{], perfEst)}

\NormalTok{inf_gain <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"inf_gain"}\NormalTok{]]}
\NormalTok{prune_se <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"prune_se"}\NormalTok{]]}

\KeywordTok{cat}\NormalTok{(}\StringTok{"Best Parameter set:"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  inf_gain : "}\NormalTok{, inf_gain,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  prune_se : "}\NormalTok{, prune_se)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Best Parameter set: 
##   inf_gain :  0.1 
##   prune_se :  0.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Train model with best parameter set for testing}
\NormalTok{information_gain <-}\StringTok{ }\KeywordTok{attrEval}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., train, }\DataTypeTok{estimator =} \StringTok{"InfGain"}\NormalTok{)}
\NormalTok{features <-}\StringTok{ }\KeywordTok{names}\NormalTok{(information_gain)[information_gain}\OperatorTok{>}\NormalTok{inf_gain]}

\NormalTok{model <-}\StringTok{ }\KeywordTok{rpartXse}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., train[,}\KeywordTok{c}\NormalTok{(}\StringTok{"wealth_index"}\NormalTok{, features)], }\DataTypeTok{se =}\NormalTok{ prune_se)}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, test, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{)}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(predicted, test}\OperatorTok{$}\NormalTok{wealth_index)}
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     470     56      0      0       0
##    Poorer       59    408     58      2       0
##    Middle        1     62    317     93       1
##    Richer        0      2     58    300      49
##    Richest       0      0      0     50     337
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results[}\StringTok{"Decision Tree"}\NormalTok{] <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\NormalTok{results[}\StringTok{"Decision Tree"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Decision Tree 
##     0.7886354
\end{verbatim}

\hypertarget{support-vector-machine}{%
\subsubsection{Support Vector Machine}\label{support-vector-machine}}

SVM creates a decision boundary between classes. Cost and gamma
parameters are evaluated by performance estimation. The test model is
trained with the optimum parameter set for the classification.

Parameter set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cost <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{gamma <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\StringTok{"svm.perf"}\NormalTok{)  }\CommentTok{# Load pre-estimated performances}
\KeywordTok{plot}\NormalTok{(perfEst)   }\CommentTok{# Plot performance estimation results}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/svm-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Best parameter set}
\NormalTok{work_flow <-}\StringTok{ }\KeywordTok{getWorkflow}\NormalTok{(}\KeywordTok{topPerformers}\NormalTok{(perfEst, }\DataTypeTok{maxs =} \OtherTok{TRUE}\NormalTok{)[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{], perfEst)}

\NormalTok{cost <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"learner.pars"}\NormalTok{]][[}\StringTok{"cost"}\NormalTok{]]}
\NormalTok{gamma <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"learner.pars"}\NormalTok{]][[}\StringTok{"gamma"}\NormalTok{]]}

\KeywordTok{cat}\NormalTok{(}\StringTok{"Best Parameter set:"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  cost  : "}\NormalTok{, cost,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  gamma : "}\NormalTok{, gamma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Best Parameter set: 
##   cost  :  10 
##   gamma :  0.01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Train model with best parameter set for testing}
\NormalTok{model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., train, }\DataTypeTok{cost =}\NormalTok{ cost, }\DataTypeTok{gamma =}\NormalTok{ gamma)}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, test, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{)}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(predicted, test}\OperatorTok{$}\NormalTok{wealth_index)}
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     503     30      0      0       0
##    Poorer       27    463     20      0       0
##    Middle        0     35    390     33       0
##    Richer        0      0     23    394      11
##    Richest       0      0      0     18     376
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results[}\StringTok{"Support Vector Machine"}\NormalTok{] <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\NormalTok{results[}\StringTok{"Support Vector Machine"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Support Vector Machine 
##              0.9151959
\end{verbatim}

\hypertarget{adabag}{%
\subsubsection{Adabag}\label{adabag}}

Bootstrap Aggregation (Bagging) is an ensemble method. The number of
iterations for boosting run and max depth is evaluated by using the
performance estimator.

Parameter set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mfinal =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{120}\NormalTok{, }\DecValTok{200}\NormalTok{)}
\NormalTok{maxdepth =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\StringTok{"adabag.perf"}\NormalTok{)  }\CommentTok{# Load pre-estimated performances}
\KeywordTok{plot}\NormalTok{(perfEst) }
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/adabag-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Best parameter set}
\NormalTok{work_flow <-}\StringTok{ }\KeywordTok{getWorkflow}\NormalTok{(}\KeywordTok{topPerformers}\NormalTok{(perfEst, }\DataTypeTok{maxs =} \OtherTok{TRUE}\NormalTok{)[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{], perfEst)}

\NormalTok{mfinal <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"mfinal"}\NormalTok{]]}
\NormalTok{maxdepth <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"maxdepth"}\NormalTok{]]}

\KeywordTok{cat}\NormalTok{(}\StringTok{"Best Parameter set:"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  mfinal   : "}\NormalTok{, mfinal,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  maxdepth : "}\NormalTok{, maxdepth)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Best Parameter set: 
##   mfinal   :  20 
##   maxdepth :  10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Train model with best parameter set for testing}
\NormalTok{model <-}\StringTok{ }\KeywordTok{bagging}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., train, }\DataTypeTok{mfinal =}\NormalTok{ mfinal, }\DataTypeTok{control =} \KeywordTok{rpart.control}\NormalTok{(}\DataTypeTok{maxdepth=}\NormalTok{maxdepth))}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, test, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{)}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(predicted}\OperatorTok{$}\NormalTok{class), test}\OperatorTok{$}\NormalTok{wealth_index)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in confusionMatrix.default(as.factor(predicted$class),
## test$wealth_index): Levels are not in the same order for reference and
## data. Refactoring data to match.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     435     85      7      2       1
##    Poorer       80    307     56      3       0
##    Middle       15    123    306    133       2
##    Richer        0     13     61    251     118
##    Richest       0      0      3     56     266
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results[}\StringTok{"Adabag"}\NormalTok{] <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\NormalTok{results[}\StringTok{"Adabag"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Adabag 
## 0.6736978
\end{verbatim}

\hypertarget{random-forest}{%
\subsubsection{Random Forest}\label{random-forest}}

Random Forest is a combination of the multiple decision trees to prevent
overfitting that comes with decision trees. The number of trees is
evaluated by using the performance estimator.

Parameter set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ntree =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\StringTok{"randomforest.perf"}\NormalTok{)  }\CommentTok{# Load pre-estimated performances}
\KeywordTok{plot}\NormalTok{(perfEst) }
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/randomforest-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Best parameter set}
\NormalTok{work_flow <-}\StringTok{ }\KeywordTok{getWorkflow}\NormalTok{(}\KeywordTok{topPerformers}\NormalTok{(perfEst, }\DataTypeTok{maxs =} \OtherTok{TRUE}\NormalTok{)[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{], perfEst)}

\NormalTok{ntree <-}\StringTok{ }\NormalTok{work_flow}\OperatorTok{@}\NormalTok{pars[[}\StringTok{"learner.pars"}\NormalTok{]][[}\StringTok{"ntree"}\NormalTok{]]}

\KeywordTok{cat}\NormalTok{(}\StringTok{"Best Parameter set:"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{  ntree  : "}\NormalTok{, ntree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Best Parameter set: 
##   ntree  :  400
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Train model with best parameter set for testing}
\NormalTok{model <-}\StringTok{ }\KeywordTok{randomForest}\NormalTok{(wealth_index }\OperatorTok{~}\StringTok{ }\NormalTok{., train, }\DataTypeTok{ntree =}\NormalTok{ ntree)}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, test, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{)}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(predicted, test}\OperatorTok{$}\NormalTok{wealth_index)}
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     496     39      0      0       0
##    Poorer       34    447     54      1       0
##    Middle        0     42    340     81       0
##    Richer        0      0     39    337      41
##    Richest       0      0      0     26     346
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results[}\StringTok{"Random Forest"}\NormalTok{] <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\NormalTok{results[}\StringTok{"Random Forest"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Random Forest 
##     0.8463194
\end{verbatim}

\hypertarget{neural-network}{%
\subsubsection{Neural Network}\label{neural-network}}

A neural network is designed that is suitable for the classification
problem. The architecture of the neural network consists of three hidden
layers. After each hidden layer dropout is applied to prevent
overfitting and ReLu is used as an activation function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_frame <-}\StringTok{ }\KeywordTok{as.h2o}\NormalTok{(train, }\StringTok{"train_frame"}\NormalTok{)}
\NormalTok{test_frame <-}\StringTok{ }\KeywordTok{as.h2o}\NormalTok{(test, }\StringTok{"test_frame"}\NormalTok{)}

\NormalTok{model <-}\StringTok{ }\KeywordTok{h2o.deeplearning}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{names}\NormalTok{(household[, }\DecValTok{-1}\NormalTok{]), }
                          \DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\StringTok{"wealth_index"}\NormalTok{), }
                          \DataTypeTok{training_frame=}\NormalTok{train_frame,}
                          \DataTypeTok{hidden =} \KeywordTok{c}\NormalTok{(}\DecValTok{196}\NormalTok{, }\DecValTok{256}\NormalTok{, }\DecValTok{128}\NormalTok{),}
                          \DataTypeTok{hidden_dropout_ratios =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                          \DataTypeTok{activation =} \StringTok{"RectifierWithDropout"}\NormalTok{,}
                          \DataTypeTok{epochs =} \DecValTok{500}\NormalTok{,}
                          \DataTypeTok{shuffle_training_data=}\OtherTok{TRUE}\NormalTok{)}

\NormalTok{predicted <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{h2o.predict}\NormalTok{(model, test_frame))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predicted}\OperatorTok{$}\NormalTok{predict <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(predicted}\OperatorTok{$}\NormalTok{predict, }
                            \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Poorest"}\NormalTok{, }\StringTok{"Poorer"}\NormalTok{, }\StringTok{"Middle"}\NormalTok{, }\StringTok{"Richer"}\NormalTok{, }\StringTok{"Richest"}\NormalTok{))}

\NormalTok{predicted}\OperatorTok{$}\NormalTok{target <-}\StringTok{ }\NormalTok{test}\OperatorTok{$}\NormalTok{wealth_index}

\NormalTok{conf_matrix <-}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(predicted}\OperatorTok{$}\NormalTok{predict, predicted}\OperatorTok{$}\NormalTok{target)}
\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction Poorest Poorer Middle Richer Richest
##    Poorest     499     28      0      0       0
##    Poorer       31    478     23      0       0
##    Middle        0     22    399     42       0
##    Richer        0      0     11    383       8
##    Richest       0      0      0     20     379
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results[}\StringTok{"Neural Network"}\NormalTok{] <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{]}
\NormalTok{results[}\StringTok{"Neural Network"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Neural Network 
##      0.9203616
\end{verbatim}

\hypertarget{results}{%
\section{Results}\label{results}}

The success of models that are trained with optimal parameter sets are
given in the following bar plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Model =} \KeywordTok{names}\NormalTok{(results), }
                \DataTypeTok{Accuracy =}\NormalTok{ results}\OperatorTok{*}\DecValTok{100}\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Model, }\DataTypeTok{weight=}\NormalTok{Accuracy)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Model"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Accuracy"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{ggtitle}\NormalTok{(}\DataTypeTok{label =} \StringTok{"Model Accuracies"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =} \KeywordTok{sprintf}\NormalTok{(}\StringTok{"%0.4f"}\NormalTok{, }\KeywordTok{round}\NormalTok{(Accuracy, }\DataTypeTok{digits =} \DecValTok{4}\NormalTok{)), }
                      \DataTypeTok{y =}\NormalTok{ Accuracy}\DecValTok{-5}\NormalTok{), }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-31-1.pdf}

According to results, Adabag achieved the worst score, decision tree,
and random forest got more success than bagging. SVM and neural network
models achieved a similar score on classification TNSA household data
for the wealth index. The neural network model is the best in evaluated
ones. Besides, misclassification is done mostly in favor of the close
class such as richer to richest.

The normalized confusion matrix of the neural network that is the best
model is given at the following plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{normalized_conf_matrix <-}\StringTok{ }\NormalTok{conf_matrix}\OperatorTok{$}\NormalTok{table }\OperatorTok{/}\StringTok{ }\KeywordTok{colSums}\NormalTok{(conf_matrix}\OperatorTok{$}\NormalTok{table)}
\NormalTok{normalized_conf_matrix <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(normalized_conf_matrix)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{  normalized_conf_matrix, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Reference, }\DataTypeTok{y =}\NormalTok{ Prediction)) }\OperatorTok{+}
\StringTok{       }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Reference"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Prediction"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{       }\KeywordTok{geom_tile}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ Freq)) }\OperatorTok{+}
\StringTok{       }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =} \KeywordTok{sprintf}\NormalTok{(}\StringTok{"%0.4f"}\NormalTok{, Freq)), }\DataTypeTok{vjust =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{       }\KeywordTok{scale_fill_gradient}\NormalTok{(}\DataTypeTok{low =} \StringTok{"white"}\NormalTok{,}
                           \DataTypeTok{high =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-32-1.pdf}

According to the confusion matrix, the neural network model is more
successful in predicting the extreme classes than the predicting to
wealth indexes in the middle.

\hypertarget{references}{%
\section{References}\label{references}}

\begin{itemize}
\tightlist
\item
  TNSA Dataset
  \url{http://www.hips.hacettepe.edu.tr/eng/population_survey.shtml}
\item
  Lecture Notes
\item
  GGPlot \url{https://ggplot2.tidyverse.org/}
\item
  R Documentations \url{https://www.rdocumentation.org/}
\item
  H2O Neural Network
  \url{http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html}
\end{itemize}

\end{document}
